# -*- coding: utf-8 -*-
"""Credit_Scoring_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y0yaJuI4pAoVOP9cmi2FH7XW2_mJfNZW
"""

# Step 2 (Fixed): Load a working credit dataset
import pandas as pd

# This is a real, publicly hosted credit scoring dataset
url = "https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv"
df = pd.read_csv(url)

# Display first few rows
df.head()

# Step 3.1: Check for missing values
df.isnull().sum()

# Step 3.2: Convert target labels (Good → 0, Bad → 1)
df['Class'] = df['Class'].map({'Good': 0, 'Bad': 1})

# Show all column names
print(df.columns)

# Step 3.2 (fixed): Convert 'credit_risk' column to numeric
df['credit_risk'] = df['credit_risk'].map({'good': 0, 'bad': 1})

df['credit_risk'].value_counts()

# Step 3.3: Select features and target
X = df[['Duration', 'Amount', 'Age']]   # Input features
y = df['Class']                         # Target: 0 = Good, 1 = Bad

# Step 3.3 (fixed): Select input features and target
X = df[['duration', 'amount', 'age']]   # Input features (correct column names)
y = df['credit_risk']                   # Target: 0 = good, 1 = bad

X.head()

# Clean the data by removing rows where credit_risk is missing
df = df.dropna(subset=['credit_risk'])

# Check again to confirm
df['credit_risk'].isnull().sum()

# Step 3.3: Select input features and target
X = df[['duration', 'amount', 'age']]   # Input features
y = df['credit_risk']                   # Target column

# Select input features and target again (overwrite previous X and y)
X = df[['duration', 'amount', 'age']]
y = df['credit_risk']

print("Missing values in y:", y.isnull().sum())

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 4: Split data into training and testing sets
from sklearn.model_selection import train_test_split

# Split the data: 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 5: Train a Logistic Regression model
from sklearn.linear_model import LogisticRegression

# Create the model
model = LogisticRegression()

# Train it using the training data
model.fit(X_train, y_train)

# Step 5: Train a Logistic Regression model
from sklearn.linear_model import LogisticRegression

# Create the model
model = LogisticRegression()

# Train the model using training data
model.fit(X_train, y_train)

# Remove rows where credit_risk is missing
df = df.dropna(subset=['credit_risk'])

# Remove all rows with any missing values
df = df.dropna()

# Select features and target after cleaning
X = df[['duration', 'amount', 'age']]
y = df['credit_risk']

y.isnull().sum()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(df.shape)

# Drop only if any of the required columns are missing
df = df.dropna(subset=['duration', 'amount', 'age', 'credit_risk'])

X = df[['duration', 'amount', 'age']]
y = df['credit_risk']

print(X.shape, y.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Number of rows in df:", len(df))
print(df.shape)
df.head()

df[['duration', 'amount', 'age', 'credit_risk']].isnull().sum()

url = "https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv"

import pandas as pd

# Reload clean credit dataset
url = "https://raw.githubusercontent.com/AnandDeopurkar/datasets/main/german_credit_cleaned.csv"
df = pd.read_csv(url)

# Select input and target
X = df[['duration', 'amount', 'age']]
y = df['credit_risk']

import pandas as pd

# Load a clean German credit dataset
url = "https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv"
df = pd.read_csv(url)

# Convert target to numeric
df['Class'] = df['Class'].map({'Good': 0, 'Bad': 1})

# Select features and target
X = df[['Duration', 'Amount', 'Age']]
y = df['Class']

# Confirm shapes
print(X.shape, y.shape)

df.columns

'credit_risk'

import pandas as pd

# Load the dataset
url = "https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv"
df = pd.read_csv(url)

# Check column names
print(df.columns)

# Convert target to numeric (0 for good, 1 for bad)
df['credit_risk'] = df['credit_risk'].map({'good': 0, 'bad': 1})

# Select features and target
X = df[['duration', 'amount', 'age']]
y = df['credit_risk']

# Check shapes
print("Shape of X:", X.shape)
print("Shape of y:", y.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)

import pandas as pd

# Load the dataset
url = "https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv"
df = pd.read_csv(url)

# Check what unique values are in the target column
print("Unique values in credit_risk:", df['credit_risk'].unique())

['good' 'bad']

['Good' 'Bad']

# Convert target to lowercase first
df['credit_risk'] = df['credit_risk'].str.lower()

# Now map it to numbers
df['credit_risk'] = df['credit_risk'].map({'good': 0, 'bad': 1})

# Drop any rows where mapping failed (i.e., credit_risk is still NaN)
df = df.dropna(subset=['credit_risk'])

import pandas as pd

# Load dataset
url = "https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv"
df = pd.read_csv(url)

# Check the actual unique values in the credit_risk column
print("Before cleanup:", df['credit_risk'].unique())

# Convert credit_risk values to string and lowercase
df['credit_risk'] = df['credit_risk'].astype(str).str.lower()

# Map 'good' -> 0 and 'bad' -> 1
df['credit_risk'] = df['credit_risk'].map({'good': 0, 'bad': 1})

# Drop any rows where mapping failed (still NaN)
df = df.dropna(subset=['credit_risk'])

# Confirm result
print("After cleanup:", df['credit_risk'].unique())

# Select input and output
X = df[['duration', 'amount', 'age']]
y = df['credit_risk']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Shape of df:", df.shape)

print(df['credit_risk'].unique())

df = pd.read_csv("https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv")
print("credit_risk unique values (original):", df['credit_risk'].unique())

import pandas as pd

# Load dataset — do NOT apply mapping!
url = "https://raw.githubusercontent.com/selva86/datasets/master/GermanCredit.csv"
df = pd.read_csv(url)

# Select input features and target
X = df[['duration', 'amount', 'age']]
y = df['credit_risk']

# Check shape to confirm it's not empty
print("X shape:", X.shape)
print("y shape:", y.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

# Predict on test set
y_pred = model.predict(X_test)

# Print metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("ROC-AUC Score:", roc_auc_score(y_test, y_pred))

# Optional: Full classification report
print("\nClassification Report:\n", classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

# Re-evaluate
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_rf))

['installment_rate', 'present_residence', 'number_credits', 'job', 'people_liable']

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Then do train-test split again

import joblib

# Save the trained Logistic Regression model to a file
joblib.dump(model, 'credit_score_model.pkl')

print("✅ Model saved as credit_score_model.pkl")

# Load the model
loaded_model = joblib.load('credit_score_model.pkl')

# Example: make predictions with it
sample_prediction = loaded_model.predict(X_test[:5])
print("Sample predictions:", sample_prediction)

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

joblib.dump(rf_model, 'credit_score_rf_model.pkl')

